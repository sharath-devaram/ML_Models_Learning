{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6401c0c4-fe11-49c2-97a7-e7233680c546",
   "metadata": {},
   "source": [
    "# RNNs GRUs LSTMs Bidirectionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31e88694-c78a-499d-b722-5ad8a627d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109b25e9-6ec5-4666-89a8-780912489832",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62897791-05e9-4690-a22a-539d1853779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test = x_test.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9069758f-0e07-4dbb-bf29-2a0eaab2796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_5 (SimpleRNN)     (None, None, 512)         276992    \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 806,922\n",
      "Trainable params: 806,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(None,28)))#we dont a aspecific dimnension for this\n",
    "model.add(\n",
    "    layers.SimpleRNN(512,return_sequences=True,activation='relu')#512 nodes, True, becuase return each time\n",
    ")\n",
    "model.add(layers.SimpleRNN(512,activation='relu'))#we can use tanh activation for GRU\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea2d2e3-e46c-4e5e-8161-d52fdec9adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e651cdaf-39ca-41a3-95a8-c4e15d614f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 130s - loss: 960.7050 - accuracy: 0.6666\n",
      "Epoch 2/10\n",
      "938/938 - 118s - loss: 2.5937 - accuracy: 0.5447\n",
      "Epoch 3/10\n",
      "938/938 - 117s - loss: 1.4074 - accuracy: 0.5028\n",
      "Epoch 4/10\n",
      "938/938 - 143s - loss: 0.9022 - accuracy: 0.6881\n",
      "Epoch 5/10\n",
      "938/938 - 161s - loss: 0.7650 - accuracy: 0.7348\n",
      "Epoch 6/10\n",
      "938/938 - 151s - loss: 0.7184 - accuracy: 0.7534\n",
      "Epoch 7/10\n",
      "938/938 - 158s - loss: 0.6840 - accuracy: 0.7748\n",
      "Epoch 8/10\n",
      "938/938 - 154s - loss: 0.6963 - accuracy: 0.7661\n",
      "Epoch 9/10\n",
      "938/938 - 154s - loss: 0.6214 - accuracy: 0.7996\n",
      "Epoch 10/10\n",
      "938/938 - 156s - loss: 1590449536.0000 - accuracy: 0.4949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1357e152a60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6e0d06-2160-470c-9639-06b70936d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 3s - loss: 110.7675 - accuracy: 0.1144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[110.76746368408203, 0.1143999993801117]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd440760-825f-4f90-be32-fea1ada683fa",
   "metadata": {},
   "source": [
    "# GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3931c41-6c7e-4b7c-ac73-1f4a1437b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 256)         219648    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 616,970\n",
      "Trainable params: 616,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#################################### another model for GRU\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(None,28)))#we dont a aspecific dimnension for this\n",
    "model.add(\n",
    "    layers.GRU(256,return_sequences=True,activation='tanh')#512 nodes, True, becuase return each time\n",
    ")\n",
    "model.add(layers.GRU(256,activation='tanh'))#we can use tanh activation\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c26f8ee-a34e-44e9-b060-b0d1b4f6bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06698b-3041-4f9d-9be1-c83432391d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b9653-ccb6-4b10-801c-6ca041f9774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test,batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e8312-2206-41d0-854b-7bfa0d14d9c7",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59197c34-bfae-438c-b8a2-acb3b0f6fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 256)         291840    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 819,722\n",
      "Trainable params: 819,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#################################### another model for LSTM\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(None,28)))#we dont a aspecific dimnension for this\n",
    "model.add(\n",
    "    layers.LSTM(256,return_sequences=True,activation='tanh')#512 nodes, True, becuase return each time\n",
    ")\n",
    "model.add(layers.LSTM(256,activation='tanh'))#we can use tanh activation\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e211c38d-a42d-4a59-8272-17c9272fc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e13c1-971b-4428-9a3f-b162dcf9d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77673cf1-245b-44ec-a53c-37f0e9fd971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test,batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6dbfe-c1b6-480d-a8f9-d14cf640ae40",
   "metadata": {},
   "source": [
    "# LSTM Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab33029-63d8-4917-bec1-213332ab1150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, None, 512)         583680    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,163,722\n",
      "Trainable params: 2,163,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#################################### another model for LSTM\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(None,28)))#we dont a aspecific dimnension for this\n",
    "model.add(\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(256,return_sequences=True,activation='tanh')#512 nodes due to bidirectional, True, becuase return each time \n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(256,activation='tanh'))#we can use tanh activation\n",
    "    )\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cda9427b-3676-41e7-92b3-88375d28d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b0087-ab15-4759-b501-c3a217faeb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08054826-ce83-4c98-a662-88d35822c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test,batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0123cc7-03f0-4345-b0c4-a3f72a864770",
   "metadata": {},
   "source": [
    "# InDepth Example for Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a161cbfe-2fdd-4408-b335-f4032a26b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7dc4bd5-5943-4538-8d1d-953bdb051dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH_SIZE =64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c595c07b-792b-4ced-910a-a82b1d054a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "train_images = os.getcwd() + \"/train_images/\" + train_df.iloc[:, 0].values\n",
    "test_images = os.getcwd() + \"/test_images/\" + test_df.iloc[:, 0].values\n",
    "\n",
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c93ec46f-fbc6-47a8-909f-d47349cea8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    # In older versions you need to set shape in order to avoid error\n",
    "    # on newer (2.3.0+) the following 3 lines can safely be removed\n",
    "    image.set_shape((64, 64, 1))\n",
    "    label[0].set_shape([])\n",
    "    label[1].set_shape([])\n",
    "\n",
    "    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8d8f57c-a116-4a27-b9cc-afdf95e8fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = (\n",
    "    test_dataset.map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ac46dda-62a6-4984-bb2c-d033de08a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64, 64, 1))\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(\n",
    "    64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "output1 = layers.Dense(10, activation=\"softmax\", name=\"first_num\")(x)\n",
    "output2 = layers.Dense(10, activation=\"softmax\", name=\"second_num\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=[output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "333bfc8a-a42e-4066-a249-b02ec61c959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
    "    loss=[\n",
    "        keras.losses.SparseCategoricalCrossentropy(),\n",
    "        keras.losses.SparseCategoricalCrossentropy(),\n",
    "    ],\n",
    "    metrics=[\"accuracy\",]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56dff474-6e76-49f5-b6b5-e8a71ed07d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_3: expected shape=(None, 28, 28, 1), found shape=(None, 64, 64, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    D:\\Anaconda\\envs\\DL-Env\\lib\\site-packages\\keras\\engine\\input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_3: expected shape=(None, 28, 28, 1), found shape=(None, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, verbose=2)\n",
    "model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41955e89-ddfe-48d6-9af2-cd9d73ce011f",
   "metadata": {},
   "source": [
    "# Model Subclassing with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3e8325d-341c-42c7-a12a-b16b082927f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1,28,28,1).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "563ec2a0-7475-4e47-a6fd-c510a8260ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN ->BatchNorm->ReLU (Common structures)-->General Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "307daf5e-a186-4e37-95ec-36f1ab852dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self,out_channels,kernel_size=3):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels,kernel_size,padding='same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "    def call(self,input_tensor,training=False):\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x,training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2e3ed29-efae-41e3-b995-eda7ce6898cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =keras.Sequential(\n",
    "    [\n",
    "        CNNBlock(32),\n",
    "        CNNBlock(64),\n",
    "        CNNBlock(128),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a4f6e63-f4a3-4bdd-82d5-d397507914ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.cnn1 = CNNBlock(channels[0], 3)\n",
    "        self.cnn2 = CNNBlock(channels[1], 3)\n",
    "        self.cnn3 = CNNBlock(channels[2], 3)\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.cnn1(input_tensor, training=training)\n",
    "        x = self.cnn2(x, training=training)\n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
    "        x = self.pooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afb1e536-bd67-41a3-ba14-55ce92a85f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Like(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_Like, self).__init__()\n",
    "        self.block1 = ResBlock([32, 32, 64])\n",
    "        self.block2 = ResBlock([128, 128, 256])\n",
    "        self.block3 = ResBlock([128, 256, 512])\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.block1(input_tensor, training=training)\n",
    "        x = self.block2(x, training=training)\n",
    "        x = self.block3(x, training=training)\n",
    "        x = self.pool(x, training=training)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(28, 28, 1))\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e4a6e67-7770-4a24-b594-7f2900a6d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_Like().model()\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[2].output\n",
    "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
    "model = keras.Model(base_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4126555-28b9-4f4c-90f0-9196ed75dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4298bd15-1f58-40d3-a86c-28c464610e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 70s - loss: 0.1025 - accuracy: 0.9682\n",
      "157/157 - 3s - loss: 0.0479 - accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as cnn_block_3_layer_call_and_return_conditional_losses, cnn_block_3_layer_call_fn, cnn_block_4_layer_call_and_return_conditional_losses, cnn_block_4_layer_call_fn, cnn_block_5_layer_call_and_return_conditional_losses while saving (showing 5 of 70). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
    "model.save(\"pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630eaa1-b03b-4f00-9980-d5006911266a",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "954404af-fa26-4241-b91a-389a10a1aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28*28).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1,28*28).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07585966-6b8d-49a7-9da6-7187afd00daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(layers.Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(Dense, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            name=\"w\",\n",
    "            shape=(input_dim, units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name=\"b\", shape=(units,), initializer=\"zeros\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8cad056-30ed-4e12-83cb-a03f3ee9ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Dense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name=\"w\",\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name=\"b\", shape=(self.units,), initializer=\"random_normal\", trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34812982-69be-41db-aea3-6522e7c0c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReLU(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyReLU, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.math.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "326770d1-73e3-4a56-b175-341bd5f3c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):  # model.fit, model.evalute, model.predict\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64)\n",
    "        self.dense2 = Dense(num_classes)\n",
    "        self.relu = MyReLU()\n",
    "\n",
    "        # self.dense1 = layers.Dense(64)\n",
    "        # self.dense3 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.relu(self.dense1(x))\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "542c2684-f22f-443c-89d4-eb89beac556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e357fd0-b5fa-4173-bdda-99080ce1f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 - 7s - loss: 1.6072 - accuracy: 0.5361\n",
      "Epoch 2/2\n",
      "1875/1875 - 6s - loss: 0.7858 - accuracy: 0.7952\n",
      "313/313 - 1s - loss: 0.6286 - accuracy: 0.8354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6285871863365173, 0.8353999853134155]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cbf215-ffcf-4da6-a9d3-e21261ea6fc6",
   "metadata": {},
   "source": [
    "# Save and Load Models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8eb97f0a-fb6c-4f16-ad80-8d8c53f30f36",
   "metadata": {},
   "source": [
    "# Alright, so here have some code which should feel familiar from previous tutorials,\n",
    "# here is what we want to cover\n",
    "# 1. How to save and load model weights\n",
    "# 2. Save and loading entire model (Serializing model)\n",
    "#   - Saves weights\n",
    "#   - Model architecture\n",
    "#   - Training Configuration (model.compile())\n",
    "#   - Optimizer and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6dcc6c9-f769-4cf3-93c5-18bb269afaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save model with model.save(\"model_name_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b321a53-5cab-466a-9b04-b5741ca105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "# model = keras.models.load_model('saved_models_here')# you can use the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "365cd3de-eabc-425e-b67c-312d26768e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "model = keras.models.load_model(\"./pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b2456c31-655b-4986-8202-d0e19614ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "res_block (ResBlock)         (None, 14, 14, 64)        28896     \n",
      "_________________________________________________________________\n",
      "res_block_1 (ResBlock)       (None, 7, 7, 256)         592512    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                125450    \n",
      "=================================================================\n",
      "Total params: 746,858\n",
      "Trainable params: 745,578\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())# we got the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6156a-4ed1-4b1d-beec-8622dbcacaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save load_weights\n",
    "# model.save_weights('checkpoint_folder/')\n",
    "#load_wights\n",
    "# model.load_weights('checkpoint_folder/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-Env-Kernel",
   "language": "python",
   "name": "dl-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
