{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f9da24-e93f-4d58-aeec-6550ed60615e",
   "metadata": {},
   "source": [
    "# Transfer Learning, Fine Tuning and Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cb6e99-3808-47bb-8c2e-e7908774ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5264a943-91d9-4df1-baea-b4944513f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Avoid GPU errors\n",
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a984b6-1ae7-4e5d-a27a-1ad4463b8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================ #\n",
    "#                  Pretrained-Model                #\n",
    "# ================================================ #\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f2277-716d-4529-9ae6-0babe608d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbaafbc-688d-4f1d-86f9-f8d04c1e986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all model layer weights\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e7ac1-7f6c-4a47-8712-c5c133974bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also set trainable for specific layers\n",
    "for layer in model.layers:\n",
    "    # assert should be true because of one-liner above\n",
    "    assert layer.trainable == False\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c221d-eebf-4751-b290-e1f92624c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())  # for finding base input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7f123-216e-4797-aa1f-b902c670732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_inputs = model.layers[0].input\n",
    "base_output = model.layers[-2].output\n",
    "output = layers.Dense(10)(base_output)\n",
    "new_model = keras.Model(base_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f448766-b95c-412c-aac7-c30437ad6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is actually identical to model we\n",
    "# loaded (this is just for demonstration and\n",
    "# and not something you would do in practice).\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b76a3d-b67a-4381-96e0-436694935a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual we do compile and fit, this time on new_model\n",
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d2b83-3b94-4e97-be48-909b2d5ff630",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(x_train, y_train, batch_size=32, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caabb1bd-011d-4465-b29b-3a6d4733b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "#                Pretrained Keras Model               #\n",
    "# =================================================== #\n",
    "# Random data for demonstration (3 examples w. 3 classes)\n",
    "x = tf.random.normal(shape=(3, 299, 299, 3))\n",
    "y = tf.constant([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4be1a0-f239-4713-80a9-fc13cde32960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.InceptionV3(include_top=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3e187-2b17-40e6-bba6-2200de087b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input you can also do model.input,\n",
    "# then for base_outputs you can obviously\n",
    "# choose other than simply removing the last one :)\n",
    "base_inputs = model.layers[0].input\n",
    "base_outputs = model.layers[-2].output\n",
    "classifier = layers.Dense(3)(base_outputs)\n",
    "new_model = keras.Model(inputs=base_inputs, outputs=classifier)\n",
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b68f67-c0e0-43a6-a1cb-66f5e80f6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_model.summary())\n",
    "new_model.fit(x, y, epochs=15, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e13d2-619c-490a-a839-01d9befae4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= #\n",
    "#                Pretrained Hub Model               #\n",
    "# ================================================= #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c750e-0d8a-473a-b8a1-2cbd60c5fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data for demonstration (3 examples w. 3 classes)\n",
    "x = tf.random.normal(shape=(3, 299, 299, 3))\n",
    "y = tf.constant([0, 1, 2])\n",
    "\n",
    "url = \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e66d47-56a6-439f-8f34-833e18ff6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = hub.KerasLayer(url, input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a07a6-ab18-4acc-9427-d20affa443a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bac28-23d0-47ab-8c22-bd2b12fbd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49494602-0caf-427d-8781-b8065b3f4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=32, epochs=15, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dea206-fffa-4770-8c67-99c8430fc6b7",
   "metadata": {},
   "source": [
    "# TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3b0fe-6adf-4fa3-a9bd-a828645c5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418083e5-f681-42d6-ae7b-2d442100f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d122edd-05e6-43e1-a1d7-5f3be23f9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = tfds.show_examples(ds_train, ds_info, rows=4, cols=4)\n",
    "# print(ds_info)\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5255ea-1853-4a90-a68c-c456de1ac8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a47a91-42d4-4e30-91cd-e75bde56ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccbcb4-0440-4d0a-9124-063875b6bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(128)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08dd41-eabf-46e3-93b5-39f5a7ed530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad827b6-31d7-4870-b71f-6935d0445bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59056e5d-589c-4033-96ff-ce9e02f22664",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446225d3-d629-4316-b156-0538dcbcbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"imdb_reviews\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3b91d-d01b-4213-afe4-555dd5589e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc0268-482c-48aa-aaaa-47c2722c04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary():\n",
    "    vocabulary = set()\n",
    "    for text, _ in ds_train:\n",
    "        vocabulary.update(tokenizer.tokenize(text.numpy().lower()))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379a0fe-3e02-4130-9d5f-2ba7273bc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = build_vocabulary()\n",
    "\n",
    "encoder = tfds.features.text.TokenTextEncoder(\n",
    "    list(vocabulary), oov_token=\"<UNK>\", lowercase=True, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62316bc0-a968-4afe-a0c8-22ebd91b4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_enc(text_tensor, label):\n",
    "    encoded_text = encoder.encode(text_tensor.numpy())\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea027ae-4f65-43a8-a757-30bd7dc82892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_map_fn(text, label):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    encoded_text, label = tf.py_function(\n",
    "        my_enc, inp=[text, label], Tout=(tf.int64, tf.int64)\n",
    "    )\n",
    "\n",
    "    # `tf.data.Datasets` work best if all components have a shape set\n",
    "    #  so set the shapes manually:\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "\n",
    "    return encoded_text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb87fc-472e-4818-ae9f-7da0bb54c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(encode_map_fn, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(1000)\n",
    "ds_train = ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(encode_map_fn)\n",
    "ds_test = ds_test.padded_batch(32, padded_shapes=([None], ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71537d7-8c2f-4e68-a1e5-3b65226bcafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value=0),\n",
    "        layers.Embedding(input_dim=len(vocabulary) + 2, output_dim=32),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192929c-a5db-4da0-9799-e425c0d70892",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(3e-4, clipnorm=1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd418732-ddb9-4b47-abc7-b89884339c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, epochs=15, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ccec0-b87d-492a-9ace-187d652726cc",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b413ba5-c8cf-4962-ab20-edb031e6a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    new_height = new_width = 32\n",
    "    image = tf.image.resize(image, (new_height, new_width))\n",
    "\n",
    "    if tf.random.uniform((), minval=0, maxval=1) < 0.1:\n",
    "        image = tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 3])\n",
    "\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.1, upper=0.2)\n",
    "\n",
    "    # a left upside down flipped is still a dog ;)\n",
    "    image = tf.image.random_flip_left_right(image)  # 50%\n",
    "    # image = tf.image.random_flip_up_down(image) #%50%\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f95eb-3d93-4775-ab15-1f94fe536a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "# ds_train = ds_train.map(augment)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(BATCH_SIZE)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# TF >= 2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c852c8-f31c-4ecc-ab68-7aded60c2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(height=32, width=32,),\n",
    "        layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomContrast(factor=0.1,),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75012f36-2a47-4ea5-b8be-1e1ced907719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((32, 32, 3)),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(4, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Conv2D(8, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4c76c-fc3b-4fde-a9b6-5f96c694b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e8ddd-f598-4724-9259-cf3ed14337b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76530ad-d3a3-428c-b1b0-ffd7a2bde585",
   "metadata": {},
   "source": [
    "# Callbacks with keras and Writing Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89edf92-8428-4907-82c6-f28a221c84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    \"checkpoint/\", save_weights_only=True, monitor=\"train_acc\", save_best_only=False,\n",
    ")\n",
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.1, patience=3, mode=\"max\", verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "class OurOwnCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get(\"accuracy\") > 1:\n",
    "            print(\"Accuracy over 70%, quitting training\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.01),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    callbacks=[save_callback, lr_scheduler, OurOwnCallback()],\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183e76f-2eb1-4fc2-a67b-03482e8c592b",
   "metadata": {},
   "source": [
    "# Customizing Model.Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9344b-718c-4c64-835b-beefaba5a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "\n",
    "\n",
    "class CustomFit(keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(CustomFit, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super(CustomFit, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Caclulate predictions\n",
    "            y_pred = self.model(x, training=True)\n",
    "\n",
    "            # Loss\n",
    "            loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Gradients\n",
    "        training_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, training_vars)\n",
    "\n",
    "        # Step with optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = self.model(x, training=False)\n",
    "\n",
    "        # Updates the metrics tracking the loss\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Update the metrics.\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "training = CustomFit(model)\n",
    "training.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "training.fit(x_train, y_train, batch_size=64, epochs=2)\n",
    "training.evaluate(x_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c234c7b-3b20-4dfc-af32-f734c45a3161",
   "metadata": {},
   "source": [
    "# Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1c40c-a175-47fb-a0a3-524648e5d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(128)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_epochs = 5\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStart of Training Epoch {epoch}\")\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(ds_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch, training=True)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "\n",
    "    train_acc = acc_metric.result()\n",
    "    print(f\"Accuracy over epoch {train_acc}\")\n",
    "    acc_metric.reset_states()\n",
    "\n",
    "# Test Loop\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(ds_test):\n",
    "    y_pred = model(x_batch, training=True)\n",
    "    acc_metric.update_state(y_batch, y_pred)\n",
    "\n",
    "train_acc = acc_metric.result()\n",
    "print(f\"Accuracy over Test Set: {train_acc}\")\n",
    "acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f636b15-de82-4e89-ac18-bbab2bf95948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-Env-Kernel",
   "language": "python",
   "name": "dl-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
