{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22698a95-7fb7-4de4-bbe7-c5b693d709c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f49a-e40b-4e9b-9c04-34aff1d06c39",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97020a3f-148b-4e9b-b474-21f0e6ec3709",
   "metadata": {},
   "source": [
    "# Perception"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c66e8205-ccba-4670-a405-454f0b69d208",
   "metadata": {},
   "source": [
    "The Perceptron is a fundamental building block of artificial neural networks. It is atype of artificial neuron designed to mimic the basic functionality of bilogical neuron. The perceptron takes multiple inputs, each multiplied by corresponding weight, and sums up these weighted inputs. it then applies an acivation function to sum to produce an output."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9acbf70-ade4-42b6-91bc-c5680614db4f",
   "metadata": {},
   "source": [
    "activation functions are:\n",
    "1. Step Function(Binary Step): Outputs 1 if the sum of weighted inputs is positive, otherwise 0.\n",
    "2. Sigmoid Function. input range between 0 & 1. suitable for binary classification problems\n",
    "3. ReLU(Rectified Linear Unit): Outputs the inputs directly if it is positive,otherwise 0. ReLU has become popular due to its simplicity and effectiveness in tarining in deep neuralnetworks\n",
    "4. Tanh Function: (Hyperbolic Tangent): Squashes the input into a range between -1 and 1, similar to the sigmoid but with centered mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b97959b-1be9-4ac0-a0ab-070b2696803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432376da-5e72-442b-a79b-6af162c88d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self,input_dim):\n",
    "        self.weights = np.random.rand(input_dim)\n",
    "        self.bias = np.random.rand()\n",
    "    def predict(self,inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights)+self.bias\n",
    "        return 1 if weighted_sum>=0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac58be2-721f-46c5-8af5-6f43e50826ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "input_data=np.array([1,0,1])\n",
    "perceptron = Perceptron(input_dim=len(input_data\n",
    "                                     ))\n",
    "prediction = perceptron.predict(input_data)\n",
    "print(\"Prediction: \",prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685943f-9391-493a-98eb-f4895f295234",
   "metadata": {},
   "source": [
    "# Multi-Layer Perception"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2089b80-86ce-455c-8aa8-0fee202f19c4",
   "metadata": {},
   "source": [
    "1. Sigmoid Function: This function maps the weighted sum of inputs to a value between 0 and 1. It is often used in the output layer for binary classification problems\n",
    "2. ReLU(Rectified Linear Unit): Outputs the inputs directly if it is positive,otherwise 0. ReLU has become popular due to its simplicity and effectiveness in tarining in deep neuralnetworks\n",
    "3. Tanh Function: (Hyperbolic Tangent): Squashes the input into a range between -1 and 1, similar to the sigmoid but with centered mean.\n",
    "4. Leaky ReLU: An improved version of ReLU that allows a small non-zero output when the weighted sum is negative. This helps to overcome some issues related to \"dying ReLU\" during training.\n",
    "5. Softmax Functions: Softmax is used in the output layer for multi-class classification problems. It converts the weighted sum of inputs into probabbilties. making it suitable for choosing the most likely class among multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fbab1f3-2e27-4262-abd6-207951c433b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "991aa7ca-7263-4a63-a7f3-6e2c691cb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Generate random data\n",
    "x = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "y = np.random.randint(2, size=100)  # Binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99def7a5-bf12-4324-9772-2f8a594a8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=10))  # Hidden layer with 32 neurons and ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron and sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09b52b85-b640-464e-aab6-175d2fb0037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d10e16a7-aedf-408e-9f5a-6b09a307855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5231 - loss: 0.7134\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.4970 - loss: 0.7199  \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4225 - loss: 0.7204 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4765 - loss: 0.7010 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4649 - loss: 0.7119 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4934 - loss: 0.7065 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5021 - loss: 0.6982 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4969 - loss: 0.6999 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4660 - loss: 0.6966 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5311 - loss: 0.6919 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e735e29040>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4268b0-3ca9-471c-a331-16a008ba14e0",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d44bbfa-bd97-4336-a495-f41d3c56ea1c",
   "metadata": {},
   "source": [
    "A CNN is a specialized type of artificial nueral network designed to process and analyse visual data, such as images and videos.\n",
    "CNN are best for open CV\n",
    "These consits of several layers:\n",
    "1. Convolutional Layers: These layers are the core of CNNs and consist of multiple learnable filters or kernels. Each filter is a small matrix that slides over the input image, scanning it for relevant patterns. The convolution operation involves element-wise multiplication of the filter and the corresponding image region, fottowed by summation. This process generates feature maps that represent the presence of specific patterns or features in different parts of the image.\n",
    "\n",
    "2. Activation Layers: After the convolution operation, an activation function (usually ReLU) is applied to introduce non-linearity to the model, allowing it to capture complex patterns effectively.\n",
    "\n",
    "3. Pooling Layers: Pooling layers downsample the feature maps, reducing their spatial dimensions and the number of parameters. Max pooling is commonly used, which retains the maximum value within a small window, effectively preserving the most important features.\n",
    "\n",
    "4. Fully Connected Layers: These layers are similar to those in traditional neural networks and serve to perform classification or regression tasks based on the learned features from the previous layers.\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are designed to automatically identify patterns and features in visual data, like images. They start with an input image and use convolutional layers with small filters to detect specific patterns by scanning the image. The results create new feature maps that highlight different patterns. Activation functions introduce non-linearity, pooling layers downsample the maps, and stacking multiple layers allows the network to learn more complex features. Fully connected layers then perform classification tasks, and during training, the network adjusts its filter weights and biases through backpropagation to improve performance. Overall, CNNs excel at image recognition and understanding visual data by progressively learning more abstract features from the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f745a85e-7593-4d6e-9afe-d391a2f5a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement a simple CNN for image classification using Python and Keras:\n",
    "import numpy as np \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c49cce11-8982-40ef-8da4-214800694d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "np.random.seed ( 42)\n",
    "# 100 images of size 28x28 with 3 color channels\n",
    "X = np. random. rand (100, 28, 28, 3)\n",
    "y = np. random. randint (10, size=100) # Labels for 10 classes (0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c36b7e4c-5ed3-451c-808c-7d79756aa9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a61147d5-0abc-4a0e-bc71-ca4603d40fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ML-Env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer with 32 filters and ReLU activation\n",
    "model. add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Max pooling layer\n",
    "model.add(Flatten()) # Flatten the output for fully connected layers\n",
    "# Fully connected output layer with 18 neurons for 10 classes and Softmax activation \n",
    "model.add(Dense(16, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaf8d3cd-233f-41ee-b7d7-1dc4466c7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db98d5a1-b5f6-488f-bdd9-4f130b9a3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0919 - loss: 2.6867\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1114 - loss: 2.4342 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1967 - loss: 2.1966 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1536 - loss: 2.1202 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2627 - loss: 2.0710 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1569 - loss: 1.9784 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5341 - loss: 1.8664 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2330 - loss: 1.8089\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3410 - loss: 1.7463 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 1.5470 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e735fc3140>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d2104-c8c5-4f47-bd53-b8f28ba424c8",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18f7e506-309d-4ced-aba8-3c231cf9f126",
   "metadata": {},
   "source": [
    "A Recurrent Neural Network (RNN) is a type of artificial neural network designed to process sequential data. Unlike traditional feedforward neural networks, RNNs have connections that create loops, allowing information to persist and be passed from one step to the next. This looping behaviour enables RNNs to capture temporal dependencies and patterns in sequences, making them well-suited for tasks like natural language processing, speech recognition, and time series analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6837f126-c908-42ef-8984-db293db4a516",
   "metadata": {},
   "source": [
    "The structure of a Recurrent Neural Network can be represented as a series of interconnected hidden states, where each hidden state represents the network's memory at a particular time step. RNNs process sequential data in the following manner:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edd73c0-7516-4e37-a680-829483618d51",
   "metadata": {},
   "source": [
    "1. Input Sequence: At each time step t, the RNN receives an input vector representing the data at that time step. For example, in natural language processing, each time step may correspond to a word or a character in a sentence.\n",
    "\n",
    "2. Hidden State: The RNN maintains a hidden state vector at each time step, which serves as its memory. The hidden state captures the information from the current input and the previous hidden state, allowing the network to remember past information.\n",
    "\n",
    "3. Recurrent Connection: The key feature of RNNs is the recurrent connection, which connects the hidden state of the one-time step to the next time step. This looping connection enables the network to share information across different time steps, making it capable of understanding the sequential nature of the data.\n",
    "\n",
    "4 . The RNN can produce an output at each time step based on the corresponding hidden state. For example, in language modelling tasks, the RNN can predict the next word in a sentence based on the previous words and their hidden states."
   ]
  },
  {
   "cell_type": "raw",
   "id": "493ba36f-0382-409f-9857-c4758dd28e26",
   "metadata": {},
   "source": [
    "At the start of the sequence, the RNN's hidden state is initialized to a fixed vector or set to zeros. As the input sequence is presented one-time step at a time, the RNN updates its hidden state using the current input and the previous hidden state. This process is repeated for each time step, allowing the network to process the entire sequence. The recurrent connection in the RNN allows information to flow from one time step to the next, creating a memory of past inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5028820-c9ac-4d54-ab1b-4ffbd46a4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d7c2674-5523-4277-a15d-0b6699f95665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample sequential data\n",
    "np. random. seed (42)\n",
    "# 100 sequences of length 10 with 1 feature\n",
    "X = np. random. rand (100, 10, 1)\n",
    "y = np. random. randint(2, size=100) # Binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef4f1a2a-2a08-45e0-8940-d8809dbc2699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ML-Env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5049 - loss: 0.7552\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5446 - loss: 0.6848 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.6822 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 0.6892 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4939 - loss: 0.6942 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 0.6815 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4925 - loss: 0.6914 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.6788 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5457 - loss: 0.6862 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: 0.6614 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e73619ba10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an RNN model\n",
    "model = Sequential()\n",
    "# RNN layer with 32 neurons\n",
    "model.add(SimpleRNN(32, input_shape=(10, 1)))\n",
    "# Output layer with 1 neuron for binary classification and Sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid' ))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model. fit(X, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b39594-44b6-4ed5-9174-93583215c04f",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory Networks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29b66f7c-4e0c-42cf-9a72-0f4acc1db90e",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM) Networks are a type of Recurrent Neural Network (RNN) that is designed to overcome the vanishing and exploding gradient problems in traditional RNNs. LSTMs are well-suited for processing sequential data with long-term dependencies, such as natural language, speech, and time series data.\n",
    "They utilize specialized memory cells and gating mechanisms to selectively retain and forget information over time, allowing them to capture relevant patterns and information across long sequences."
   ]
  },
  {
   "cell_type": "raw",
   "id": "450921a1-ce7e-4f0e-a81c-14ee113f2629",
   "metadata": {},
   "source": [
    "The structure of an LSTM can be understood as a sequence of memory cells, each equipped with three gating mechanisms that control the flow of information:\n",
    "\n",
    "Input Gate: The input gate determines which parts of the input should be stored in the memory cell. It takes into account the current input and the previous hidden state and outputs a value between 0 and 1 for each input element, indicating the relevance of the input for the current memory cell.\n",
    "\n",
    "Forget Gate: The forget gate determines which information in the memory cell should be discarded. It takes into account the current input and the previous hidden state and outputs a value between 0 and 1 for each element in the memory cell, indicating the importance of retaining the information.\n",
    "\n",
    "Output Gate: The output gate determines what information from the memory cell should be passed to the next time step.\n",
    "It takes into account the current input and the previous hidden state and outputs a value between 0 and 1 for each element in the memory cell, indicating the contribution of the information to the final output.\n",
    "\n",
    "The LSTM memory cell itself operates in the following steps:\n",
    "\n",
    "• Input Processing: The input gate and the current input are used to update the memory cell's contents with relevant information from the input.\n",
    "• Forget Processing: The forget gate and the previous memory cell contents are used to decide which information needs to be discarded from the memory cell.\n",
    "• Output Processing: The output gate and the updated memory cell contents are used to compute the output of the LSTM for the current time step.\n",
    "\n",
    "At the start of the sequence, the LSTM's hidden state and memory cell are initialized to fixed vectors or set to zeros. As the input sequence is presented one-time step at a time, the LSTM updates its hidden state and memory cell using the input and the previous hidden state. The gating mechanisms (input gate, forget gate, and output gate) control the flow of information into and out of the memory cell, selectively retaining and forgetting information as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7de70016-2b1e-4c3f-9173-dba64f5b47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dd46ea6-eb7d-424f-823f-597fc4d140b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample sequential data\n",
    "np.random.seed(42)\n",
    "# 100 sequences of length 10 with 1 feature\n",
    "X = np.random.rand(100, 10, 1)\n",
    "y = np.random.randint(2, size=100) # Binary labels (8 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e1a4a5d-18e6-4cbb-9f7e-716fc1baf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 1))) # LSTM layer with 32 neurons\n",
    "\n",
    "# Output layer with 1 neuron for binary classification and Sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1705b33-db0a-43aa-9f2e-6416a3c204c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5217 - loss: 0.6925\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5184 - loss: 0.6922 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5247 - loss: 0.6916 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5007 - loss: 0.6938 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5163 - loss: 0.6924 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 0.6898 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6926 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5257 - loss: 0.6912 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5465 - loss: 0.6888 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5257 - loss: 0.6915 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e73781aae0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de90eb-dc7c-48b4-be53-246ce826997a",
   "metadata": {},
   "source": [
    "# Generative Adversial Networks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50e94026-f744-4b39-a321-d24364fe99dc",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks (GANs) are a class of deep learning models that consist of two neural networks, the generator and the discriminator, engaged in a game-like competition. \n",
    "\n",
    "GANs are used to generate new data samples that resemble a given dataset. The generator network generates fake samples, and the discriminator network evaluates whether the samples are real (from the original dataset) or fake (generated by the generator).\n",
    "\n",
    "Through this adversarial process, GANs learn to produce increasingly realistic data samples, leading to impressive results in generating images, videos, music, and other types of data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e65cbd6-3715-42a5-8e98-57f87db108f8",
   "metadata": {},
   "source": [
    "Generator Network: The generator is responsible for creating fake data samples that resemble real data. It takes random noise as input and transforms it into data samples that should look like they belong to the original dataset. The generator consists of several layers that gradually transform the noise into more complex patterns, generating data samples that become increasingly realistic as the training progresses.\n",
    "\n",
    "Discriminator Network: The discriminator is the adversary of the generator. It acts as a binary classifier and is trained to distinguish between real data samples from the original dataset and fake data samples generated by the generator.\n",
    "The discriminator also consists of several layers that process the input data and make a decision about its authenticity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4515abd2-8635-4839-8c13-d9023d1c66eb",
   "metadata": {},
   "source": [
    "Let's understand how GANs work. The generator and discriminator networks are initialized with random weights. The generator takes random noise as input and generates fake data samples. The discriminator evaluates both real data samples from the original dataset and fake data samples from the generator. It classifies them as real or fake, respectively. The generator's objective is to produce fake data samples that are indistinguishable from real data, aiming to fool the discriminator. The discriminator's objective is to correctly classify real and fake data samples.\n",
    "\n",
    "The generator and discriminator networks are trained alternately, with the generator trying to improve its ability to generate realistic samples while the discriminator tries to become more accurate in distinguishing real from fake samples.\n",
    "\n",
    "The generator and discriminator networks engage in an adversarial game-like competition, where the generator tries to deceive the discriminator with increasingly realistic samples, and the discriminator tries to become more skilled at detecting fake samples. Over time, through this adversarial learning process, the generator becomes better at generating high-quality data samples, and the discriminator becomes more accurate in identifying real from fake samples.\n",
    "\n",
    "Let's implement a simple Generative Adversarial Network for generating images using Python and Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470d8bf-4e11-436a-b68a-e1c816d1187b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25d232-4b67-48b5-bab3-a79ab7a6ff53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3893ab-5dd4-494c-baf6-1a9b44710c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d83164-0ac8-4a27-907d-46db63f287be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset of random noise\n",
    "np. random. seed (42)\n",
    "# 100 samples of random noise with 100 dimensions\n",
    "X_noise = np. random. rand (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62b42c3-f2cb-4f4b-bba8-6a0f43a66fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator model\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=100))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(Dense (512))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "# Output layer with 784 neurons for 28x28 images\n",
    "generator.add(Dense (784, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ccacc1e-5f5c-47cb-9cd1-0c31734d7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a discriminator model\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(512, input_dim=784))\n",
    "discriminator.add(LeakyReLU(alpha=0.01))\n",
    "discriminator.add(Dense (256))\n",
    "discriminator.add(LeakyReLU(alpha=0.01))\n",
    "# Output layer with 1 neuron for binary classification\n",
    "discriminator.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1787f34f-7222-4bc8-a2d7-81c176298f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "# Create a GAN model by combining the generator and discriminator\n",
    "discriminator.trainable = False # Freeze the discriminator during GAN training\n",
    "gan = Sequential()\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)\n",
    "# Compile the GAN\n",
    "gan.compile(optimizer=Adam(learning_rate=8.0082, beta_1=0.5), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc05c2c0-982d-4911-ab46-cb2d87bbb702",
   "metadata": {},
   "source": [
    "• Generate fake images using the generator by passing random noise as input.\n",
    "• Select a random batch of real images from the original dataset.\n",
    "• Concatenate the real and fake images to create a combined batch for training the discriminator.\n",
    "• Create labels for the discriminator: 0.9 for real images (one-sided label smoothing for stability) and 0 for fake images.\n",
    "• Train the discriminator on the combined batch of real and fake images.\n",
    "• Generate new noise for the generator.\n",
    "• Create labels for the generator: 1 (real) because we want the discriminator to mistake fake images for real.\n",
    "• Train the GAN (generator only) on the new noise and the tabets for the generator.\n",
    "• Print the discriminator and GAN losses to monitor the training progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e26e1-161e-457c-a336-e37fdd314511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2362596c-289a-4559-81de-4754d553e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 samples of real images wath 784 dimensions (28x28 images flattened)\n",
    "X_real = np.random.rand (1000, 784)\n",
    "# Fit the GAN model\n",
    "epochs = 10000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62f7043-61dd-4835-af44-7ed80e2287fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs) :\n",
    "    # Generate fake images using the generator\n",
    "    noise = np.random.rand(batch_size, 100)\n",
    "    fake_images = generator.predict(noise)\n",
    "    # Select a random batch of real images from the original dataset\n",
    "    idx = np.random.randint(0, X_real.shape[0], batch_size)\n",
    "    real_images = X_real[idx]\n",
    "    # Concatenate real and fake images to create a batch for training the discriminator\n",
    "    X_combined = np.concatenate([real_images, fake_images])\n",
    "    # Labels for the discriminator: 1 for real images, 0 for fake images\n",
    "    y_discriminator = np.zeros(2 * batch_size)\n",
    "    y_discriminator[:batch_size] = 0.9 # One-sided label smoothing for stability\n",
    "    # Train the discriminator\n",
    "    discriminator_loss = discriminator.train_on_batch(X_combined, y_discriminator)\n",
    "    # Generate new noise for the generator\n",
    "    noise = np.random.rand(batch_size, 100)\n",
    "    # Labels for the generator: 1 (real) because we want the discriminator to mistake fake images as real\n",
    "    y_generator = np.ones(batch_size)\n",
    "    # Train the GAN (generator only)\n",
    "    gan_loss = gan.train_on_batch(noise, y_generator)\n",
    "    # Print the progress\n",
    "    if epoch % 100 == 0:\n",
    "        print (f\"Epoch {epoch} | Discriminator Loss: {discriminator_loss} | GAN LOSs:{gan_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a1fbb-7460-4e95-835b-3c8311276c73",
   "metadata": {},
   "source": [
    "# Transformer Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940ad3a-ccc0-43b5-b4f3-4eea1f506563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizers, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae41cc-735f-4d5d-affb-78dcc9b9004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff5cf5-f8ec-42b0-bc0a-373d8bf335d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input text for masked langugae modeling\n",
    "text = \"The quick brown[MASK] jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea7127-105d-47cf-b3d8-f5d0f4a8b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer the input text\n",
    "inputs = tokenizer(text,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4c06f-865a-45a5-b26d-99ce17ea69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the masked token index\n",
    "masked_index = torch.where(inputs['input_ids'][0]==tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dcad7-41eb-4a3f-987b-68f4e26cd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict missing word using the pre-trained BERT model\n",
    "with torch.no_grad():\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits[0,masked_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77308f47-f4bf-47f0-ab6e-efb89f3f9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top predicted tokens and thier probablities\n",
    "top_predictions = torch.topk(predictions,k=5,dim=1)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(top_predictions.indices[0])\n",
    "predicted_probablities = top_predictions.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea04b0-9edc-4c70-9872-28c987a4e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, probabilty in zip(predicted_tokens,predicted_probabilities):\n",
    "print(f\"{token}:{probabilty:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d70d370-8e1d-4970-9fa6-1d71413f01d8",
   "metadata": {},
   "source": [
    "The structure of Transformer Networks is based on self-attention mechanisms, where each position in the input sequence can attend to all other positions. The key components of Transformer Networks include:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f67765d-c867-4714-b033-be14ffe666b5",
   "metadata": {},
   "source": [
    "• Encoder: The encoder takes the input sequence and processes it through multiple layers of self-attention and feed-forward neural networks. The self-attention mechanism allows the model to weigh the importance of each position in the input sequence based on its relationship with all other positions.\n",
    "The output of the encoder is a set of context-aware representations for each position in the input sequence.\n",
    "\n",
    "• Decoder: The decoder also consists of multiple layers of self-attention and feed-forward neural networks. It takes the output of the encoder and generates the output sequence step-by-step. During decoding, each position can only attend to previous positions in the output sequence to ensure autoregressive generation.\n",
    "\n",
    "• Self-Attention Mechanism: The self-attention mechanism in Transformer Networks allows each position in the sequence to attend to all other positions, capturing dependencies and context more effectively compared to traditional recurrent neural networks.\n",
    "\n",
    "• Feed-Forward Neural Networks: The feed-forward neural networks within each layer of the encoder and decoder provide additional non-linear transformations to the sequence representations.\n",
    "\n",
    "Let's understand how Transformer Networks work. The input sequence is first embedded into continuous vector representations, which allow the model to understand the semantics of the tokens. The mput embeddings are passed through muttiple encoder layers. Each encoder layer performs self-attention, allowing each position in the input sequence to attend to all other positions and compute an attention score based on their relevance to the current position."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6a8b119-1e14-4254-8ba1-98617fb5e223",
   "metadata": {},
   "source": [
    "After self-attention, the representations are passed through feed-forward neural networks, adding non-linearity and additional context. During the decoding process (in sequence-to-sequence tasks), the decoder attends to the previously generated positions in the output sequence using self-attention. Additionally, it can attend to the encoder's output to extract relevant information needed for decoding.\n",
    "The decoder produces the output sequence step-by-step, generating one token at a time autoregressively. The process continues until the end-of-sequence token is generated.\n",
    "\n",
    "Implementing a complete Transformer Network from scratch in Python can be quite complex. However, you can use popular deep learning libraries such as TensorFlow or PyTorch, which provide pre-built Transformer models and APis to facilitate their use in various tasks like machine translation and language modelling. Let's take a high-level look at how to use a Transformer model using Hugging Face's \"transformers\" library in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1a517-20df-46d4-b605-984aceb3992a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
